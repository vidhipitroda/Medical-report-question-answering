# ğŸ©º Medical Document Q&A System

A prototype for extracting structured data from medical forms and answering questions based on the extracted content.

![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Gradio](https://img.shields.io/badge/UI-Gradio-orange)

---

## ğŸ“Œ Project Overview

This project was developed to address the **manual burden of extracting information from medical documents**. In real-world clinical environments, healthcare providers deal with large volumes of patient forms. The goal is to **automate information extraction and enable Q&A interaction with medical forms**, making workflows more efficient.

---

## ğŸ¯ Objective

- Take an **image of a medical form**
- Extract structured data using OCR and layout detection
- Let users **ask questions** based on the document
- Return the **answer** visually and textually
1. ğŸ“¤ User uploads a medical form image
2. ğŸ§¼ Image preprocessing (grayscale, contrast enhancement)
3. ğŸ§­ Layout detection using  YOLO
4. ğŸ” OCR text extraction using Tesseract
5. ğŸ§¾ Convert text into structured format
6. ğŸ§  Run Q&A model to find the answer to the userâ€™s question
7. ğŸŒ Display result in Gradio interface with highlights

